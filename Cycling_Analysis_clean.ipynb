{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2636c60a",
   "metadata": {},
   "source": [
    "# Exploartion\n",
    "\n",
    "How does cycling in Stockholm change once autumn break ends and the city becomes darker, colder, and busier?\n",
    "I built this data analysis project to explore how cyclist behavior shifts before and after höstlov, and what factors might explain those patterns."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cabb409",
   "metadata": {},
   "source": [
    "## 1. Data Loading and Cleaning:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8829cb86",
   "metadata": {},
   "source": [
    "## 2. Exploratory Data Analysis (EDA)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01b76239",
   "metadata": {},
   "source": [
    "### 2.1 Overall cycling level"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25c40a71",
   "metadata": {},
   "source": [
    "#### Do cycling volumes decrease or increase in gerneral after höstlov?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1af4f2cb",
   "metadata": {},
   "source": [
    "So overall, cycling activity dropped by around 65 000 trips per week, or 14 %, after week 43.\n",
    "Wilcoxon test: W = 0.000, p = 0.0039\n",
    "→ This test is significant (p < 0.01).\n",
    "It confirms that, across most years, week 45 has lower cycling counts than week 43."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6b78d55",
   "metadata": {},
   "source": [
    "#### How do cycling volumes on the same streets differ between the week before and the week after Höstlov?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46f70787",
   "metadata": {},
   "source": [
    "### 2.2 Effect of Light on cycling level"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "705e5742",
   "metadata": {},
   "source": [
    "#### Does street lighting influence wether people continue cycling after höstlov?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75db9f96",
   "metadata": {},
   "source": [
    "#### Do less people cycle in the dark hours after sunset?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "001bf3dc",
   "metadata": {},
   "source": [
    "### 2.3 cycling route changes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16150f8e",
   "metadata": {},
   "source": [
    "#### Do cyclist switch to different routes after höstlov?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93742c72",
   "metadata": {},
   "source": [
    "### 2.4 Effect of Weather on cycling level"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7535a95",
   "metadata": {},
   "source": [
    "#### Do cycling volumes decrease because of the drop in temperature?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ac7b9cd",
   "metadata": {},
   "source": [
    "#### Do cycling volumes decrease because of the increase in rainfall?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b7a9d8d",
   "metadata": {},
   "source": [
    "### 2.5 Effect of traffic environment on cycling level"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11c7ee24",
   "metadata": {},
   "source": [
    "#### Do cyclists avoid shared bike-pedestrian paths routes, particularly at night due to less visibility?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c435e78f",
   "metadata": {},
   "source": [
    "#### Do cyclists avoid Side-by-side opposing cycle lanes, particularly at night due to less visibility?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cc2fe61",
   "metadata": {},
   "source": [
    "#### Do bidirectional cycle lanes experience lower cyclist volumes?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee0fe21a",
   "metadata": {},
   "source": [
    "### Summary\n",
    "\n",
    "text \n",
    "text text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49964f0d",
   "metadata": {},
   "source": [
    "## Primary Conclusion\n",
    "text\n",
    "text\n",
    "text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9302f07b",
   "metadata": {},
   "source": [
    "# Presentation (\"Flipping the Pyramid\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0694bc0",
   "metadata": {},
   "source": [
    "## Executive Summary\n",
    "text\n",
    "text text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dab6bd7",
   "metadata": {},
   "source": [
    "## 1. Key finding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b227497",
   "metadata": {},
   "source": [
    "## 2. Key finding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e7e1c50",
   "metadata": {},
   "source": [
    "## 3. Key finding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ffeae76",
   "metadata": {},
   "source": [
    "## 4. Key finding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ddf9ca6",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "95fb44d4",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8368b405",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import requests\n",
    "import pytz\n",
    "from astral import LocationInfo\n",
    "from astral.sun import sun\n",
    "from scipy import stats\n",
    "\n",
    "sns.set(style=\"whitegrid\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "128e8d49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load core datasets\n",
    "\n",
    "df_dst = pd.read_csv('stockholm_dst_end_2015_2025.csv', encoding='utf-8')\n",
    "df_cykel = pd.read_csv('td_cykel_15_min_2015-2024.csv', encoding='ascii', sep=';')\n",
    "df_platser = pd.read_csv('platser_cykel_2015-2024.csv', encoding='utf-8', sep=';')\n",
    "df_hostlov = pd.read_csv('hostlov_2015_2023.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d38d16f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Core cleaning and feature engineering for all later analyses\n",
    "\n",
    "# Basic tidy-up\n",
    "df_cykel = df_cykel.drop(columns=['direction'])\n",
    "\n",
    "# Convert hostlov dates\n",
    "df_hostlov['Start'] = pd.to_datetime(df_hostlov['Start'])\n",
    "df_hostlov['End'] = pd.to_datetime(df_hostlov['End'])\n",
    "\n",
    "# DST date parsing\n",
    "df_dst['Date'] = pd.to_datetime(df_dst['Date'], format='%d-%b-%y', errors='coerce')\n",
    "\n",
    "# Cycling timestamps: UTC -> Stockholm local\n",
    "df_cykel['timestamp_utc'] = pd.to_datetime(df_cykel['tidsstampel'], utc=True, errors='coerce')\n",
    "df_cykel = df_cykel.dropna(subset=['timestamp_utc'])\n",
    "df_cykel['timestamp_local'] = df_cykel['timestamp_utc'].dt.tz_convert('Europe/Stockholm')\n",
    "\n",
    "# Numeric fields\n",
    "df_cykel['matplats_id'] = pd.to_numeric(df_cykel['matplats_id'], errors='coerce').astype('Int64')\n",
    "df_cykel['antal'] = pd.to_numeric(df_cykel['antal'], errors='coerce').astype('Int64')\n",
    "\n",
    "# Time parts\n",
    "df_cykel['date_local'] = df_cykel['timestamp_local'].dt.date\n",
    "df_cykel['hour_local'] = df_cykel['timestamp_local'].dt.hour\n",
    "df_cykel['dow_local'] = df_cykel['timestamp_local'].dt.day_name()\n",
    "df_cykel['year'] = df_cykel['timestamp_local'].dt.year\n",
    "\n",
    "# Remove skewed / problematic data\n",
    "# outlier: matplats_id 6633 in 2015\n",
    "df_cykel = df_cykel[~((df_cykel['matplats_id'] == 6633) & (df_cykel['year'] == 2015))].copy()\n",
    "\n",
    "# Drop incomplete years 2024-2025\n",
    "df_cykel = df_cykel[~df_cykel['year'].isin([2024, 2025])].copy()\n",
    "\n",
    "# ISO year/week for all rows\n",
    "iso_all = df_cykel['timestamp_local'].dt.isocalendar()\n",
    "df_cykel['iso_year'] = iso_all.year.astype(int)\n",
    "df_cykel['iso_week'] = iso_all.week.astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "25d35694",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper functions used throughout the analysis\n",
    "\n",
    "def add_week_aggregate(df, weeks=(43, 45)):\n",
    "    \"\"\"Return df aggregated by matplats_id, iso_year, iso_week for selected weeks.\"\"\"\n",
    "    temp = df[df['iso_week'].isin(weeks)].copy()\n",
    "    agg = (\n",
    "        temp.groupby(['matplats_id', 'iso_year', 'iso_week'], as_index=False)['antal']\n",
    "        .sum()\n",
    "        .rename(columns={'antal': 'total_cyclists'})\n",
    "    )\n",
    "    return agg\n",
    "\n",
    "\n",
    "def pivot_week_change(weekly_df, week_a=43, week_b=45):\n",
    "    \"\"\"Pivot week-wise totals and compute percentage change from week_a to week_b.\"\"\"\n",
    "    pivot = (\n",
    "        weekly_df\n",
    "        .pivot(index=['matplats_id', 'iso_year'], columns='iso_week', values='total_cyclists')\n",
    "        .rename(columns={week_a: 'week' + str(week_a), week_b: 'week' + str(week_b)})\n",
    "        .reset_index()\n",
    "    )\n",
    "    col_a = 'week' + str(week_a)\n",
    "    col_b = 'week' + str(week_b)\n",
    "    valid = pivot.dropna(subset=[col_a, col_b]).copy()\n",
    "    valid['pct_change'] = (valid[col_b] - valid[col_a]) / valid[col_a] * 100\n",
    "    return pivot, valid\n",
    "\n",
    "\n",
    "def mark_hostlov_period(df, hostlov_df):\n",
    "    \"\"\"Add a boolean column in_hostlov based on hostlov start/end per year.\"\"\"\n",
    "    df = df.copy()\n",
    "    df['in_hostlov'] = False\n",
    "    for _, row in hostlov_df.iterrows():\n",
    "        mask = (df['timestamp_local'] >= row['Start']) & (df['timestamp_local'] <= row['End'])\n",
    "        df.loc[mask, 'in_hostlov'] = True\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "61a30e1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matplats with 2 or fewer usable years for week 43->45 change:\n",
      "     matplats_id  n_years\n",
      "1           6326        0\n",
      "2           6327        0\n",
      "3           6337        0\n",
      "4           6345        0\n",
      "5           6346        0\n",
      "..           ...      ...\n",
      "69          6627        1\n",
      "70          6628        1\n",
      "130         8293        1\n",
      "85          6647        2\n",
      "131         8294        2\n",
      "\n",
      "[84 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "# Week 43 vs 45 analysis shared for multiple plots\n",
    "\n",
    "weekly_totals = add_week_aggregate(df_cykel, weeks=(43, 45))\n",
    "pivot_all, pivot_valid = pivot_week_change(weekly_totals, week_a=43, week_b=45)\n",
    "\n",
    "years_per_site = (\n",
    "    pivot_valid.groupby('matplats_id')['iso_year']\n",
    "    .nunique()\n",
    "    .reset_index(name='n_years')\n",
    ")\n",
    "\n",
    "all_sites = df_cykel[['matplats_id']].drop_duplicates().sort_values('matplats_id')\n",
    "years_per_site_full = all_sites.merge(years_per_site, on='matplats_id', how='left')\n",
    "years_per_site_full['n_years'] = years_per_site_full['n_years'].fillna(0).astype(int)\n",
    "\n",
    "few_year_sites = years_per_site_full[years_per_site_full['n_years'] <= 2]\n",
    "\n",
    "print('Matplats with 2 or fewer usable years for week 43->45 change:')\n",
    "print(few_year_sites.sort_values(['n_years', 'matplats_id']))\n",
    "\n",
    "# Detailed summary for those sites\n",
    "detailed_all = (\n",
    "    pivot_all.merge(few_year_sites[['matplats_id']], on='matplats_id', how='inner')\n",
    "    .sort_values(['matplats_id', 'iso_year'])\n",
    ")\n",
    "\n",
    "detailed_all = detailed_all.merge(\n",
    "    pivot_valid[['matplats_id', 'iso_year', 'pct_change']],\n",
    "    on=['matplats_id', 'iso_year'],\n",
    "    how='left'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a5fb64b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   matplats_id           tidsstampel  antal  year  month  dag  \\\n",
      "0         6265  2015-01-01T01:45:00Z      1  2015      1    1   \n",
      "1         6265  2015-01-01T02:00:00Z      1  2015      1    1   \n",
      "2         6265  2015-01-01T02:45:00Z      1  2015      1    1   \n",
      "3         6265  2015-01-01T03:45:00Z      1  2015      1    1   \n",
      "4         6265  2015-01-01T06:15:00Z      1  2015      1    1   \n",
      "\n",
      "              timestamp_utc           timestamp_local  date_local  hour_local  \\\n",
      "0 2015-01-01 01:45:00+00:00 2015-01-01 02:45:00+01:00  2015-01-01           2   \n",
      "1 2015-01-01 02:00:00+00:00 2015-01-01 03:00:00+01:00  2015-01-01           3   \n",
      "2 2015-01-01 02:45:00+00:00 2015-01-01 03:45:00+01:00  2015-01-01           3   \n",
      "3 2015-01-01 03:45:00+00:00 2015-01-01 04:45:00+01:00  2015-01-01           4   \n",
      "4 2015-01-01 06:15:00+00:00 2015-01-01 07:15:00+01:00  2015-01-01           7   \n",
      "\n",
      "  dow_local  iso_year  iso_week  \n",
      "0  Thursday      2015         1  \n",
      "1  Thursday      2015         1  \n",
      "2  Thursday      2015         1  \n",
      "3  Thursday      2015         1  \n",
      "4  Thursday      2015         1  \n"
     ]
    }
   ],
   "source": [
    "print(df_cykel.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "53cc47ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Year       Date Day of Week  ISO Week  from      to\n",
      "0  2015 2015-10-25      Sunday        43  3:00   02:00\n",
      "1  2016 2016-10-30      Sunday        43  3:00   02:00\n",
      "2  2017 2017-10-29      Sunday        43  3:00   02:00\n",
      "3  2018 2018-10-28      Sunday        43  3:00   02:00\n",
      "4  2019 2019-10-27      Sunday        43  3:00   02:00\n"
     ]
    }
   ],
   "source": [
    "print(df_dst.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "41fab8b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   MätplatsID         Mätplatsnamn  \\\n",
      "0        6522             C0620X01   \n",
      "1        6525             C0619X01   \n",
      "2        6646  C 0306 Munkbroleden   \n",
      "3        6345             C0439X01   \n",
      "4        6346             C0439X02   \n",
      "\n",
      "                                 MätplatsBeskrivning              Sträcka  \\\n",
      "0                             Ulvsundavägen, ID 126V        Ulvsundavägen   \n",
      "1                                Brommaplan, ID 126N  Drottningholmsvägen   \n",
      "2                       Cykelbana längs Munkbroleden         Munkbroleden   \n",
      "3         NYNÄSVÄGEN del SÖNDAGSVÄGEN - MÅNDAGSVÄGEN  NYNÄSVÄGEN cykelväg   \n",
      "4  NYNÄSVÄGEN del SKÖNSTAHOLMSVÄGEN - LESJÖFORSGRÄND           Nynäsvägen   \n",
      "\n",
      "          RiktplatsA      RiktplatsB                                   R1  \\\n",
      "0    Lillsjönäsvägen    Ulvsundaplan      Lillsjönäsvägen => Ulvsundaplan   \n",
      "1        Riksbyvägen      Brommaplan            Riksbyvägen => Brommaplan   \n",
      "2         Kåkbrinken    Munkbrogatan           Kåkbrinken => Munkbrogatan   \n",
      "3       Söndagsvägen    Måndagsvägen         Söndagsvägen => Måndagsvägen   \n",
      "4  Skönstaholmsvägen  LESJÖFORSGRÄND  Skönstaholmsvägen => LESJÖFORSGRÄND   \n",
      "\n",
      "                                    R2  \\\n",
      "0      Ulvsundaplan => Lillsjönäsvägen   \n",
      "1            Brommaplan => Riksbyvägen   \n",
      "2           Munkbrogatan => Kåkbrinken   \n",
      "3         Måndagsvägen => Söndagsvägen   \n",
      "4  LESJÖFORSGRÄND => Skönstaholmsvägen   \n",
      "\n",
      "                           koordinater.mätpunkter.R1  \\\n",
      "0                 MultiPoint(148182.062 6580006.315)   \n",
      "1                 MultiPoint(146773.321 6580457.744)   \n",
      "2  MultiPoint(153799.137 6578761.995, 153799.392 ...   \n",
      "3                 MultiPoint(155560.319 6571602.942)   \n",
      "4                 MultiPoint(155667.064 6570933.234)   \n",
      "\n",
      "                           koordinater.mätpunkter.R2  \n",
      "0                 MultiPoint(148186.869 6580008.833)  \n",
      "1                 MultiPoint(146770.117 6580448.589)  \n",
      "2  MultiPoint(153795.475 6578761.08, 153795.197 6...  \n",
      "3                 MultiPoint(155562.608 6571607.519)  \n",
      "4                   MultiPoint(155673.93 6570931.86)  \n"
     ]
    }
   ],
   "source": [
    "print(df_platser.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "35f2f915",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['direction'] not found in axis\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m df_cykel \u001b[38;5;241m=\u001b[39m df_cykel\u001b[38;5;241m.\u001b[39mdrop(columns\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdirection\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "File \u001b[1;32mc:\\Users\\Lara.Maier\\AppData\\Local\\anaconda3\\Lib\\site-packages\\pandas\\core\\frame.py:5581\u001b[0m, in \u001b[0;36mDataFrame.drop\u001b[1;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[0;32m   5433\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdrop\u001b[39m(\n\u001b[0;32m   5434\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   5435\u001b[0m     labels: IndexLabel \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   5442\u001b[0m     errors: IgnoreRaise \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraise\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   5443\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   5444\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   5445\u001b[0m \u001b[38;5;124;03m    Drop specified labels from rows or columns.\u001b[39;00m\n\u001b[0;32m   5446\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   5579\u001b[0m \u001b[38;5;124;03m            weight  1.0     0.8\u001b[39;00m\n\u001b[0;32m   5580\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 5581\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mdrop(\n\u001b[0;32m   5582\u001b[0m         labels\u001b[38;5;241m=\u001b[39mlabels,\n\u001b[0;32m   5583\u001b[0m         axis\u001b[38;5;241m=\u001b[39maxis,\n\u001b[0;32m   5584\u001b[0m         index\u001b[38;5;241m=\u001b[39mindex,\n\u001b[0;32m   5585\u001b[0m         columns\u001b[38;5;241m=\u001b[39mcolumns,\n\u001b[0;32m   5586\u001b[0m         level\u001b[38;5;241m=\u001b[39mlevel,\n\u001b[0;32m   5587\u001b[0m         inplace\u001b[38;5;241m=\u001b[39minplace,\n\u001b[0;32m   5588\u001b[0m         errors\u001b[38;5;241m=\u001b[39merrors,\n\u001b[0;32m   5589\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\Lara.Maier\\AppData\\Local\\anaconda3\\Lib\\site-packages\\pandas\\core\\generic.py:4788\u001b[0m, in \u001b[0;36mNDFrame.drop\u001b[1;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[0;32m   4786\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m axis, labels \u001b[38;5;129;01min\u001b[39;00m axes\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m   4787\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m labels \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 4788\u001b[0m         obj \u001b[38;5;241m=\u001b[39m obj\u001b[38;5;241m.\u001b[39m_drop_axis(labels, axis, level\u001b[38;5;241m=\u001b[39mlevel, errors\u001b[38;5;241m=\u001b[39merrors)\n\u001b[0;32m   4790\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m inplace:\n\u001b[0;32m   4791\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_inplace(obj)\n",
      "File \u001b[1;32mc:\\Users\\Lara.Maier\\AppData\\Local\\anaconda3\\Lib\\site-packages\\pandas\\core\\generic.py:4830\u001b[0m, in \u001b[0;36mNDFrame._drop_axis\u001b[1;34m(self, labels, axis, level, errors, only_slice)\u001b[0m\n\u001b[0;32m   4828\u001b[0m         new_axis \u001b[38;5;241m=\u001b[39m axis\u001b[38;5;241m.\u001b[39mdrop(labels, level\u001b[38;5;241m=\u001b[39mlevel, errors\u001b[38;5;241m=\u001b[39merrors)\n\u001b[0;32m   4829\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 4830\u001b[0m         new_axis \u001b[38;5;241m=\u001b[39m axis\u001b[38;5;241m.\u001b[39mdrop(labels, errors\u001b[38;5;241m=\u001b[39merrors)\n\u001b[0;32m   4831\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m axis\u001b[38;5;241m.\u001b[39mget_indexer(new_axis)\n\u001b[0;32m   4833\u001b[0m \u001b[38;5;66;03m# Case for non-unique axis\u001b[39;00m\n\u001b[0;32m   4834\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\Lara.Maier\\AppData\\Local\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:7070\u001b[0m, in \u001b[0;36mIndex.drop\u001b[1;34m(self, labels, errors)\u001b[0m\n\u001b[0;32m   7068\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mask\u001b[38;5;241m.\u001b[39many():\n\u001b[0;32m   7069\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m errors \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m-> 7070\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlabels[mask]\u001b[38;5;241m.\u001b[39mtolist()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not found in axis\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   7071\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m indexer[\u001b[38;5;241m~\u001b[39mmask]\n\u001b[0;32m   7072\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdelete(indexer)\n",
      "\u001b[1;31mKeyError\u001b[0m: \"['direction'] not found in axis\""
     ]
    }
   ],
   "source": [
    "df_cykel = df_cykel.drop(columns=['direction'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "421904b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_cykel.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "387ce8e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "zero_count = (df_cykel['antal'] == 0).sum()\n",
    "print(\"Zero values in antal:\", zero_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef63bd56",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_dst.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab0053b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_cykel.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78231120",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_platser.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11a5dc17",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_hostlov.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7987a39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert start and end columns into datetime objects\n",
    "df_hostlov['Start'] = pd.to_datetime(df_hostlov['Start'])\n",
    "df_hostlov['End'] = pd.to_datetime(df_hostlov['End'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68d3196b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_hostlov.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "760a23bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract year directly from the already-cleaned timestamp_local\n",
    "df_cykel['year'] = df_cykel['timestamp_local'].dt.year\n",
    "\n",
    "# Group by year and count total cyclists and number of measurements\n",
    "year_summary = (\n",
    "    df_cykel.groupby('year', as_index=False)\n",
    "    .agg(\n",
    "        total_cyclists=('antal', 'sum'),\n",
    "        measurements=('antal', 'count')\n",
    "    )\n",
    "    .sort_values('year')\n",
    ")\n",
    "\n",
    "print(year_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de41e618",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop skewed years (2024 and 2025)\n",
    "df_cykel = df_cykel[~df_cykel['year'].isin([2024, 2025])].copy()\n",
    "\n",
    "print(\"Remaining years in df_cykel:\", sorted(df_cykel['year'].dropna().unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e04f9ceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_cykel.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "396feacb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 10. Detailed summary only for sites with ≤2 years (including years where change could NOT be calculated) ---\n",
    "\n",
    "# 1) Merge pivot_all with few_year_sites to keep only matplats_id with n_years <= 2\n",
    "detailed_all = (\n",
    "    pivot_all.merge(few_year_sites[[\"matplats_id\"]], on=\"matplats_id\", how=\"inner\")\n",
    "             .sort_values([\"matplats_id\", \"year\"])\n",
    ")\n",
    "\n",
    "# 2) Bring pct_change from pivot_valid (only for rows where both weeks exist)\n",
    "detailed_all = detailed_all.merge(\n",
    "    pivot_valid[[\"matplats_id\", \"year\", \"pct_change\"]],\n",
    "    on=[\"matplats_id\", \"year\"],\n",
    "    how=\"left\"\n",
    ")\n",
    "\n",
    "# Now detailed_all has:\n",
    "# - matplats_id, year\n",
    "# - week43, week45 (can be  if missing)\n",
    "# - pct_change ( where either week was missing)\n",
    "\n",
    "print(\"\\nDetailed summary (week43, week45, pct_change) for sites with ≤2 years (including non-calculable years):\")\n",
    "print(\n",
    "    detailed_all[[\"matplats_id\", \"year\", \"week43\", \"week45\", \"pct_change\"]]\n",
    "    .to_string(\n",
    "        index=False,\n",
    "        formatters={\n",
    "            \"week43\": lambda x: \"\" if pd.isna(x) else \"{:,.0f}\".format(x),\n",
    "            \"week45\": lambda x: \"\" if pd.isna(x) else \"{:,.0f}\".format(x),\n",
    "            \"pct_change\": lambda x: \"\" if pd.isna(x) else \"{:.1f}%\".format(x)\n",
    "        }\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df05bc57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 11. List of matplats_id to exclude (sites with ≤2 valid years, including 0) ---\n",
    "exclude_ids = sorted(few_year_sites[\"matplats_id\"].unique().tolist())\n",
    "\n",
    "print(\"\\nmatplats_id to EXCLUDE in future plots (≤2 years of usable week 43→45 change, including 0-year sites):\")\n",
    "print(exclude_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5c4d821",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6627, 6628, 6635, 6647, 8293, 8294 not enough data to analyze week 43 and 45\n",
    "# 6647, 6648, 6729 mätningsplats works on battery and had huge outagges and that led to unrealistic cyling volumes\n",
    "\n",
    "ids_to_remove = [6647, 6648, 6729, 6627, 6628, 6635, 6647, 8293, 8294]\n",
    "\n",
    "# totals BEFORE removing IDs\n",
    "total_antal_before = df_cykel['antal'].sum()\n",
    "total_rows_before = df_cykel.shape[0]\n",
    "\n",
    "# how much cyclist volume would be removed\n",
    "removed_antal = df_cykel[df_cykel['matplats_id'].isin(ids_to_remove)]['antal'].sum()\n",
    "removed_rows = df_cykel[df_cykel['matplats_id'].isin(ids_to_remove)].shape[0]\n",
    "\n",
    "# reduction in %\n",
    "removed_pct = (removed_antal / total_antal_before) * 100\n",
    "\n",
    "print(f\" Total cyclists BEFORE removal: {total_antal_before:,}\")\n",
    "print(f\" Cyclists removed (antal): {removed_antal:,}\")\n",
    "print(f\" Percentage removed: {removed_pct:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ac0d9e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6627, 6628, 6635, 6647, 8293, 8294 not enough data to analyze week 43 and 45\n",
    "# 6647, 6648, 6729 mätningsplats works on battery and had huge outagges and that led to unrealistic cyling volumes\n",
    "\n",
    "# IDs to remove completely\n",
    "ids_to_remove = [6647, 6648, 6729, 6627, 6628, 6635, 6647, 8293, 8294]\n",
    "\n",
    "# Remove from df_cykel\n",
    "df_cykel = df_cykel[~df_cykel['matplats_id'].isin(ids_to_remove)].copy()\n",
    "\n",
    "# Remove from df_platser\n",
    "df_platser = df_platser[~df_platser['MätplatsID'].isin(ids_to_remove)].copy()\n",
    "\n",
    "print(\"✔️ Unwanted IDs removed from df_cykel and df_platser\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cb804a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "display(Image(filename=\"Magelungsvägen.png\"))\n",
    "\n",
    "# no cyclepath lighting for more than 400 meters\n",
    "# the highway lighting is not sufficient for safe cycling in autumn/winter evenings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "791b8777",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "display(Image(filename=\"Örbyleden.png\"))\n",
    "\n",
    "# no cyclepath lighting for more than 500 meters\n",
    "# the highway lighting is not sufficient for safe cycling in autumn/winter evenings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30d89d90",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "display(Image(filename=\"Hjorthagen.png\"))\n",
    "\n",
    "# the distances between lighting points are too long some distances are more than 60 meters\n",
    "# they create dark zones along the cycle path making it unsafe for cyclists in autumn/winter evenings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db7662ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# I choose the year I want to look at\n",
    "YEAR = 2023\n",
    "\n",
    "# I set the timezone and location information for Stockholm\n",
    "TZ = 'Europe/Stockholm'\n",
    "LAT = 59.3293\n",
    "LON = 18.0686\n",
    "CITY_NAME = \"Stockholm\"\n",
    "\n",
    "# I set the start and end dates for October and November of the chosen year\n",
    "start_date = pd.Timestamp(f'{YEAR}-10-01')\n",
    "end_date = pd.Timestamp(f'{YEAR}-11-30 23:59:59')\n",
    "\n",
    "# I make sure timestamp_local has no timezone (so they match)\n",
    "df_cykel['timestamp_local_naive'] = df_cykel['timestamp_local'].dt.tz_localize(None)\n",
    "\n",
    "# I keep only the data between these two dates\n",
    "mask = (df_cykel['timestamp_local_naive'] >= start_date) & (df_cykel['timestamp_local_naive'] <= end_date)\n",
    "df_sel = df_cykel.loc[mask, ['timestamp_local_naive', 'antal']].copy()\n",
    "\n",
    "# I add up the number of cyclists per day\n",
    "daily = (\n",
    "    df_sel\n",
    "    .set_index('timestamp_local_naive')\n",
    "    .resample('D')['antal']\n",
    "    .sum()\n",
    "    .to_frame(name='daily_total')\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "# I create some helper columns for easier plotting and display\n",
    "daily['date_local'] = daily['timestamp_local_naive']\n",
    "daily['date_only'] = daily['timestamp_local_naive'].dt.date\n",
    "daily['date_str'] = daily['timestamp_local_naive'].dt.strftime('%Y-%m-%d')\n",
    "\n",
    "# I get the location info for Stockholm so I can calculate sunrise and sunset\n",
    "location = LocationInfo(name=CITY_NAME, region=\"Sweden\", timezone=TZ, latitude=LAT, longitude=LON)\n",
    "tzinfo = pytz.timezone(TZ)\n",
    "\n",
    "# I prepare empty lists to store sunrise and sunset information\n",
    "sunrise_list, sunset_list = [], []\n",
    "sunrise_str, sunset_str = [], []\n",
    "sunrise_hour, sunset_hour = [], []\n",
    "\n",
    "# I go through each date and calculate the sunrise and sunset times\n",
    "for idx, row in daily.iterrows():\n",
    "    date = row['date_only']\n",
    "    try:\n",
    "        s = sun(location.observer, date=date, tzinfo=tzinfo)\n",
    "        sr, ss = s['sunrise'], s['sunset']\n",
    "    except Exception:\n",
    "        sr = ss = None\n",
    "\n",
    "    if (sr is None) or (ss is None):\n",
    "        sunrise_list.append(pd.NaT)\n",
    "        sunset_list.append(pd.NaT)\n",
    "        sunrise_str.append(None)\n",
    "        sunset_str.append(None)\n",
    "        sunrise_hour.append(np.nan)\n",
    "        sunset_hour.append(np.nan)\n",
    "        continue\n",
    "\n",
    "    # I convert the times to Stockholm local and remove the timezone\n",
    "    sr_naive = sr.astimezone(tzinfo).replace(tzinfo=None)\n",
    "    ss_naive = ss.astimezone(tzinfo).replace(tzinfo=None)\n",
    "\n",
    "    sunrise_list.append(sr_naive)\n",
    "    sunset_list.append(ss_naive)\n",
    "    sunrise_str.append(sr_naive.strftime('%H:%M:%S'))\n",
    "    sunset_str.append(ss_naive.strftime('%H:%M:%S'))\n",
    "    sunrise_hour.append(sr_naive.hour + sr_naive.minute / 60)\n",
    "    sunset_hour.append(ss_naive.hour + ss_naive.minute / 60)\n",
    "\n",
    "# I add all these values back into my dataframe\n",
    "daily['sunrise'] = sunrise_list\n",
    "daily['sunset'] = sunset_list\n",
    "daily['sunrise_str'] = sunrise_str\n",
    "daily['sunset_str'] = sunset_str\n",
    "daily['sunrise_hour'] = sunrise_hour\n",
    "daily['sunset_hour'] = sunset_hour\n",
    "\n",
    "# I create an interactive chart with daily cycling totals and sunrise/sunset times\n",
    "fig = go.Figure()\n",
    "\n",
    "# I add the bar chart for daily cycling totals\n",
    "fig.add_trace(\n",
    "    go.Bar(\n",
    "        x=daily['date_local'],\n",
    "        y=daily['daily_total'],\n",
    "        name='Cyclists per day',\n",
    "        marker_color='steelblue',\n",
    "        hovertemplate='Date: %{x|%Y-%m-%d}<br>Total cyclists: %{y}<extra></extra>'\n",
    "    )\n",
    ")\n",
    "\n",
    "# I add the line for sunrise times\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=daily['date_local'],\n",
    "        y=daily['sunrise_hour'],\n",
    "        name='Sunrise (hour)',\n",
    "        mode='lines+markers',\n",
    "        line=dict(color='orange', dash='dash'),\n",
    "        hovertemplate='Date: %{x|%Y-%m-%d}<br>Sunrise: %{customdata[0]}<extra></extra>',\n",
    "        customdata=daily[['sunrise_str']].values,\n",
    "        yaxis='y2'\n",
    "    )\n",
    ")\n",
    "\n",
    "# I add the line for sunset times\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=daily['date_local'],\n",
    "        y=daily['sunset_hour'],\n",
    "        name='Sunset (hour)',\n",
    "        mode='lines+markers',\n",
    "        line=dict(color='red', dash='dash'),\n",
    "        hovertemplate='Date: %{x|%Y-%m-%d}<br>Sunset: %{customdata[0]}<extra></extra>',\n",
    "        customdata=daily[['sunset_str']].values,\n",
    "        yaxis='y2'\n",
    "    )\n",
    ")\n",
    "\n",
    "# I adjust the layout of the chart\n",
    "fig.update_layout(\n",
    "    title=f'Daily Cycling Volumes and Sunrise/Sunset Times — Oct & Nov {YEAR} (Stockholm)',\n",
    "    xaxis_title='Date',\n",
    "    yaxis=dict(title='Total cyclists per day', side='left'),\n",
    "    yaxis2=dict(title='Hour of day (sunrise/sunset)', overlaying='y', side='right', range=[0, 24]),\n",
    "    legend=dict(orientation='h', yanchor='bottom', y=1.02, xanchor='left', x=0),\n",
    "    hovermode='x unified',\n",
    "    xaxis_tickformat='%Y-%m-%d',\n",
    "    xaxis_tickangle=-45,\n",
    "    margin=dict(l=60, r=60, t=80, b=120)\n",
    ")\n",
    "\n",
    "# I show the chart\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99d24983",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The biggest decline in cycling happens after the clocks change at the end of October, when: darkness arrives earlier (16:00–17:00)\n",
    "# evening commutes fall into dark hours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0010aefc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# I make sure the timestamp column is in datetime format\n",
    "df_cykel['timestamp_local'] = pd.to_datetime(df_cykel['timestamp_local'])\n",
    "\n",
    "# I only keep data from 2015 to 2023\n",
    "mask = (df_cykel['timestamp_local'].dt.year >= 2015) & (df_cykel['timestamp_local'].dt.year <= 2023)\n",
    "df_cykel = df_cykel.loc[mask]\n",
    "\n",
    "# I create new columns for date and hour\n",
    "df_cykel['date'] = df_cykel['timestamp_local'].dt.date\n",
    "df_cykel['hour'] = df_cykel['timestamp_local'].dt.hour\n",
    "\n",
    "# I count how many cyclists there were per date and hour\n",
    "heatmap_df = df_cykel.groupby(['date', 'hour'], as_index=False)['antal'].sum()\n",
    "\n",
    "# I create a heatmap that shows when most cyclists were active\n",
    "fig = px.density_heatmap(\n",
    "    heatmap_df,\n",
    "    x='hour',\n",
    "    y='date',\n",
    "    z='antal',\n",
    "    color_continuous_scale='YlOrRd',\n",
    "    labels={'hour': 'Hour of Day', 'date': 'Date', 'antal': 'Number of Cyclists'},\n",
    "    title='Cycling Traffic Heatmap — 2015 to 2023'\n",
    ")\n",
    "\n",
    "# I make sure every hour appears on the x-axis\n",
    "fig.update_xaxes(dtick=1)\n",
    "\n",
    "# I keep the date order on the y-axis\n",
    "fig.update_yaxes(type='category')\n",
    "\n",
    "# I show the heatmap\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f36fb3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# I make sure my timestamp column is in the right format\n",
    "df_cykel['timestamp_local'] = pd.to_datetime(df_cykel['timestamp_local'], errors='coerce')\n",
    "\n",
    "# I remove rows where the timestamp is missing\n",
    "df_cykel = df_cykel.dropna(subset=['timestamp_local'])\n",
    "\n",
    "# I extract useful time information\n",
    "df_cykel['date'] = df_cykel['timestamp_local'].dt.date\n",
    "df_cykel['hour'] = df_cykel['timestamp_local'].dt.hour\n",
    "iso = df_cykel['timestamp_local'].dt.isocalendar()\n",
    "df_cykel['year'] = iso.year.astype(int)\n",
    "df_cykel['week'] = iso.week.astype(int)\n",
    "\n",
    "# I keep only data from week 43 between 2015 and 2023\n",
    "df_w43 = df_cykel[\n",
    "    (df_cykel['week'] == 43) &\n",
    "    (df_cykel['year'].between(2015, 2023))\n",
    "]\n",
    "\n",
    "# I check that I have data for this period\n",
    "if df_w43.empty:\n",
    "    raise ValueError(\"No data available for week 43 (2015–2023) in this dataset.\")\n",
    "\n",
    "# I count how many cyclists there were each hour of each day\n",
    "hourly_day = (\n",
    "    df_w43.groupby(['date', 'hour'], as_index=False)['antal']\n",
    "    .sum()\n",
    ")\n",
    "\n",
    "# I create a box plot to see how cycling changes by hour\n",
    "fig = px.box(\n",
    "    hourly_day,\n",
    "    x='hour',\n",
    "    y='antal',\n",
    "    points='all',  # I show all individual data points\n",
    "    labels={\n",
    "        'hour': 'Hour of Day (local time)',\n",
    "        'antal': 'Cyclists per Hour',\n",
    "    },\n",
    "    title='Cycling Traffic by Hour — Week 43 (2015–2023)'\n",
    ")\n",
    "\n",
    "# I make the chart easier to read\n",
    "fig.update_layout(\n",
    "    xaxis=dict(dtick=1),\n",
    "    yaxis_title='Cyclist Count per Hour',\n",
    "    hovermode='x unified'\n",
    ")\n",
    "\n",
    "# I show the plot\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6e8b360",
   "metadata": {},
   "outputs": [],
   "source": [
    "# I make sure my timestamp column is in the right format\n",
    "df_cykel['timestamp_local'] = pd.to_datetime(df_cykel['timestamp_local'], errors='coerce')\n",
    "\n",
    "# I remove rows where the timestamp is missing\n",
    "df_cykel = df_cykel.dropna(subset=['timestamp_local'])\n",
    "\n",
    "# I extract useful time information\n",
    "df_cykel['date'] = df_cykel['timestamp_local'].dt.date\n",
    "df_cykel['hour'] = df_cykel['timestamp_local'].dt.hour\n",
    "iso = df_cykel['timestamp_local'].dt.isocalendar()\n",
    "df_cykel['year'] = iso.year.astype(int)\n",
    "df_cykel['week'] = iso.week.astype(int)\n",
    "\n",
    "# I keep only data from week 45 between 2015 and 2023\n",
    "df_w45 = df_cykel[\n",
    "    (df_cykel['week'] == 45) &\n",
    "    (df_cykel['year'].between(2015, 2023))\n",
    "]\n",
    "\n",
    "# I check that I have data for this period\n",
    "if df_w45.empty:\n",
    "    raise ValueError(\"No data available for week 45 (2015–2023) in this dataset.\")\n",
    "\n",
    "# I count how many cyclists there were each hour of each day\n",
    "hourly_day = (\n",
    "    df_w45.groupby(['date', 'hour'], as_index=False)['antal']\n",
    "    .sum()\n",
    ")\n",
    "\n",
    "# I create a box plot to see how cycling changes by hour\n",
    "fig = px.box(\n",
    "    hourly_day,\n",
    "    x='hour',\n",
    "    y='antal',\n",
    "    points='all',  # I show all individual data points\n",
    "    labels={\n",
    "        'hour': 'Hour of Day (local time)',\n",
    "        'antal': 'Cyclists per Hour',\n",
    "    },\n",
    "    title='Cycling Traffic by Hour — Week 45 (2015–2023)'\n",
    ")\n",
    "\n",
    "# I make the chart easier to read\n",
    "fig.update_layout(\n",
    "    xaxis=dict(dtick=1),\n",
    "    yaxis_title='Cyclist Count per Hour',\n",
    "    hovermode='x unified'\n",
    ")\n",
    "\n",
    "# I show the plot\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fbcaa61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# I create a period column based on the hour of the day\n",
    "def period_of_day(hour):\n",
    "    if 6 <= hour <= 9:\n",
    "        return 'Morning (06–09)'\n",
    "    elif 10 <= hour <= 15:\n",
    "        return 'Midday (10–15)'\n",
    "    elif 16 <= hour <= 20:\n",
    "        return 'Evening (16–20)'\n",
    "    else:\n",
    "        return 'Night (21–05)'\n",
    "\n",
    "# I make sure the hour column exists\n",
    "df_cykel['hour'] = df_cykel['timestamp_local'].dt.hour\n",
    "\n",
    "# I add the period column\n",
    "df_cykel['period'] = df_cykel['hour'].apply(period_of_day)\n",
    "\n",
    "# I group the data by path and time of day to see which periods exist\n",
    "period_presence = (\n",
    "    df_cykel\n",
    "    .groupby(['matplats_id', 'period'])['antal']\n",
    "    .count()              # I count how many measurements exist\n",
    "    .reset_index()        # I turn the grouped data back into a dataframe\n",
    "    .pivot(               # I create columns for each period\n",
    "        index='matplats_id',\n",
    "        columns='period',\n",
    "        values='antal'\n",
    "    )\n",
    ")\n",
    "\n",
    "# I show the first 15 paths to check which periods have data\n",
    "print(period_presence.head(15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df5ba09b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# I check which time periods exist for each path\n",
    "period_counts = (\n",
    "    df_cykel\n",
    "    .groupby(['matplats_id', 'period'])['antal']\n",
    "    .count()\n",
    "    .reset_index()\n",
    "    .pivot(index='matplats_id', columns='period', values='antal')\n",
    ")\n",
    "\n",
    "print(period_counts.head(15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89633fe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#e.g. The +397,984 value for Midday (10–15) means that, when you total up all the data from 2015–2023, there were about 397,984 fewer midday cycling trips in week 45 compared to week 43.\n",
    "# After week 43, people cycled much less in the middle of the day and in the evenings, but morning cycling actually went up a bit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7453c569",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cycling in Stockholm is strongly daylight-dependent.\n",
    "# The darker it gets, the fewer people continue cycling — especially in the evening."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29216df9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# no real shift in cyle routs more a reduction over all in cyclist amount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8b2e25b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Open-Meteo Historical Weather API\n",
    "# # Weather Data: Temperature, Precipitation, and Daylight (Stockholm, 2015–2023)\n",
    "\n",
    "import requests\n",
    "from tqdm.notebook import tqdm  # progress bar for multiple years\n",
    "\n",
    "# Coordinates for Stockholm\n",
    "lat, lon = 59.3293, 18.0686\n",
    "\n",
    "# Years to fetch\n",
    "years = range(2015, 2024)\n",
    "\n",
    "# Container for all years\n",
    "frames = []\n",
    "\n",
    "print(\"Fetching weather data from Open-Meteo...\")\n",
    "\n",
    "for year in tqdm(years):\n",
    "    start_date = f\"{year}-01-01\"\n",
    "    end_date = f\"{year}-12-31\"\n",
    "\n",
    "    url = (\n",
    "        f\"https://archive-api.open-meteo.com/v1/archive\"\n",
    "        f\"?latitude={lat}&longitude={lon}\"\n",
    "        f\"&start_date={start_date}&end_date={end_date}\"\n",
    "        f\"&daily=temperature_2m_mean,precipitation_sum,daylight_duration\"\n",
    "        f\"&timezone=Europe/Stockholm\"\n",
    "    )\n",
    "\n",
    "    resp = requests.get(url, timeout=30)\n",
    "    resp.raise_for_status()  # raise an error if something fails\n",
    "    data = resp.json()\n",
    "\n",
    "    if \"daily\" not in data:\n",
    "        print(f\"⚠️ No data for {year}\")\n",
    "        continue\n",
    "\n",
    "    df_year = pd.DataFrame(data[\"daily\"])\n",
    "    df_year[\"date\"] = pd.to_datetime(df_year[\"time\"])\n",
    "    frames.append(df_year)\n",
    "\n",
    "# Combine all years\n",
    "df_weather = pd.concat(frames, ignore_index=True)\n",
    "\n",
    "# Clean and rename columns\n",
    "df_weather = df_weather.rename(\n",
    "    columns={\n",
    "        \"temperature_2m_mean\": \"temp_mean\",\n",
    "        \"precipitation_sum\": \"precip_sum\",\n",
    "        \"daylight_duration\": \"daylight_seconds\",\n",
    "    }\n",
    ")\n",
    "\n",
    "# Convert daylight to hours\n",
    "df_weather[\"daylight_hours\"] = df_weather[\"daylight_seconds\"] / 3600\n",
    "\n",
    "# Add year and ISO week\n",
    "df_weather[\"year\"] = df_weather[\"date\"].dt.year\n",
    "df_weather[\"week\"] = df_weather[\"date\"].dt.isocalendar().week\n",
    "\n",
    "# Show a preview\n",
    "print(df_weather.head())\n",
    "print(df_weather.tail())\n",
    "\n",
    "# Weekly aggregation\n",
    "weekly_weather = (\n",
    "    df_weather.groupby([\"year\", \"week\"], as_index=False)\n",
    "    .agg(\n",
    "        temp_mean=(\"temp_mean\", \"mean\"),\n",
    "        precip_total=(\"precip_sum\", \"sum\"),\n",
    "        daylight_mean=(\"daylight_hours\", \"mean\")\n",
    "    )\n",
    ")\n",
    "\n",
    "print(\"\\n✅ Finished building weekly weather dataset!\")\n",
    "print(weekly_weather.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f260111",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The three opposing-direction cycling paths (IDs 6686, 6671, and 6680) account for 7,213 lost cyclists, representing 19.3% of the entire cyclist volume drop observed across the Top-20 highest-decline cycling paths in Stockholm.\n",
    "# Interpretation:\n",
    "#\n",
    "# Opposing-direction cycling lanes make up 3 out of the 20 Top-20 paths\n",
    "# → that is 15% of all high-drop routes.\n",
    "#\n",
    "# However, these 3 paths account for 19.3% of the total cyclist drop\n",
    "# → almost 20% of all lost cyclists.\n",
    "#\n",
    "# This means their impact (~20%) is larger than their representation (15%),\n",
    "# indicating that opposing-direction lanes contribute more strongly to the\n",
    "# overall decline than would be expected based on their number alone."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
